< DOCTYPE html>
    <html lang="en">
      <head>
        <title>Reading Responses</title>
      </head>
    <body>
      <h1>Reading and Writing Response #2</h1>
        
      <p>Media is like a dimension of uncertain curiosity. We go to it for entertainment, updated articles, recipes, recommendations, news, even advice, etc., and though there is a reason we go to it and it’s a habit, it also makes us distrust it and wonder if certain things are actually real or fake. The particular ‘fakes’ that seem real in the form of images but aren’t, Malik describes as AI slop, a distortion of reality. I think the depiction of real and emotional situations has turned into a sort of comedic benefit. When accounts like the White House are posting a studio ghilbi-style photo, to appeal to people, of a Dominican woman being handcuffed, as Malik mentioned, it really makes you second-guess if the account is even the real white house and if this sort of unserious way of presenting a real circumstance is supposed to be normal. These photos spread, and I go viral, but it seems like it’s for a ‘laugh’ and in favour of the particular party that posted it. It’s posted for a comedic benefit at the expense of the seriousness it portrays or is based on. I, too, agree that AI is just an advanced version of traditional propaganda and is providing too many versions of fake narratives. AI also feeds off the algorithm, which already shows you the biases you may have, especially towards a particular situation. When Malik mentions an elderly relative who receives an AI content sent by someone they trust, and it’s content that fits their desires, it’s easy for them not to think twice about whether it’s real or not, since it fits their preferences. Sadly, this is also what people make money off of, a hoax, a sham of storytelling through AI photos that disperses throughout the internet. It’s not even a work of art that formed from someone's idea that can be interpreted in many ways, as shown in lecture class, but a photo created to mock or mislead by making it seem minor when it's major. The development of AI is also showcasing biases against diversity, equity, and inclusion, amongst other photos of a clearly white supremacist and autocratic past, shown in an ‘admirable and nostalgic’ way, which is crazy to understand when you look up a definition on AI and read that it’s a computer system that generates ‘human intelligence’. AI is accurately described as ‘the new aesthetic of fascism’, which seems like steps backwards from movements and fights for years to gain acknowledgement and non-violent treatment towards minority groups. Why progress or use it in a way that isn’t benefiting anyone, just making people more anxious and cautious of what they see, when it’s supposed to be helpful? When you're bombarded with different content, and you come across things that seem too horrific or too immoral to visually understand, Malik wrote, “The result is profound disorientation. You can’t believe your eyes, but also what can you believe if not your eyes?” I think this line really perfectly describes the back-and-forth relationship people may have with the digital media and AI’s involvement in it. How are you supposed to determine if an image is real or fake if your eyes themselves can’t tell until you open the comments and someone says it’s AI? Even if it’s simply a cute animal snuggling with another, you probably didn’t know it was just the product of instructions given to AI to generate, because it’s a harmless, adorable animal, but these harmless acts create real harm when it’s political opinions, people’s real lives, and influential narratives that are just instructions given to AI to generate. When does the line get drawn? </p>

        <h2><a href="index.html">Homepage</a></h2> <h2><a href="readings.html">Readings</a></h2>
        
    </body>
    </html>
</DOCTYPE>
